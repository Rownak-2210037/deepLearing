## AI Research
It's the starting of Neural networks

**Name:** Md. Rownak Mridha Mahi 

**Department:** Electrical and Computer Engineering (ECE) 

**Email:** mahimridha15@gmail.com  

**Institution:** RUET  

## About Project
- This project focuses on understanding and implementing core neural network models, starting from MLP and ANN to modern architectures like Transformers and LLMs.
- Both mathematical foundations (forward and backpropagation) and practical implementations are explored.
- The repository includes theory, MATLAB/Python code, and small experiments for each model.

## Topics Covered
- Artificial Neural Networks (ANN)
- Multi-Layer Perceptron (MLP)
- Forward Propagation
- Backpropagation (Mathematical Derivation)
- Support Vector Machine (SVM)
- Decision Tree
- Recurrent Neural Network (RNN)
- Long Short-Term Memory (LSTM)
- Transformer Architecture
- Introduction to Large Language Models (LLMs)

## Tools & Technologies
- Python 3.10
- PyTorch 2.0
- Jupyter Notebook
- Git & GitHub

## Future Research Goals
- Develop a deeper theoretical understanding of neural network optimization and generalization.
- Extend MLP implementations toward deeper and more complex architectures.
- Explore sequence modeling using RNN and LSTM for temporal data.
- Study attention mechanisms and Transformer-based models.
- Transition toward research on Large Language Models (LLMs) and their applications.

## Learning Objectives
- Understand the mathematical foundations of MLP and ANN
- Derive and implement forward and backpropagation
- Compare classical ML models with neural networks
- Build intuition for advanced architectures like Transformers and LLMs
